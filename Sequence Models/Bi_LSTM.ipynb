{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXgw4SuL3MyiMpo4zNTm0k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshav-b/PyTorch/blob/master/Sequence%20Models/Bi_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_aSQzWLeiwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBZgFJKsckJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYTV3f3Ic7Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = \"\"\"\n",
        "And who are you\n",
        "The proud lord said\n",
        "That I must bow so low\n",
        "Only a cat of a different coat\n",
        "That's all the truth I know\n",
        "\n",
        "In a coat of gold or a coat of red\n",
        "A lion still has claws\n",
        "And mine are long and sharp, my lord\n",
        "As long and sharp as yours\n",
        "\n",
        "\n",
        "And so he spoke, and so he spoke\n",
        "That lord of Castamere\n",
        "But now the rains weep o'er his hall\n",
        "With no one there to hear\n",
        "Yes, now the rains weep o'er his hall\n",
        "And not a soul to hear\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIMcUv58c8q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = vocab.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQMYhd7gc-cB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_dict = {w: i for i, w in enumerate(list(set(vocab.split())))}\n",
        "number_dict = {i: w for i, w in enumerate(list(set(vocab.split())))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i_Empz5dA5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6dbb55a4-5c96-4634-bb0f-be8191c0ea70"
      },
      "source": [
        "word_dict"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 23,\n",
              " 'all': 7,\n",
              " 'and': 52,\n",
              " 'are': 0,\n",
              " 'as': 46,\n",
              " 'bow': 35,\n",
              " 'but': 32,\n",
              " 'castamere': 11,\n",
              " 'cat': 16,\n",
              " 'claws': 27,\n",
              " 'coat': 1,\n",
              " 'different': 40,\n",
              " 'gold': 17,\n",
              " 'hall': 12,\n",
              " 'has': 19,\n",
              " 'he': 8,\n",
              " 'hear': 41,\n",
              " 'his': 9,\n",
              " 'i': 2,\n",
              " 'in': 37,\n",
              " 'know': 31,\n",
              " 'lion': 3,\n",
              " 'long': 50,\n",
              " 'lord': 44,\n",
              " 'low': 10,\n",
              " 'mine': 20,\n",
              " 'must': 45,\n",
              " 'my': 4,\n",
              " 'no': 49,\n",
              " 'not': 13,\n",
              " 'now': 33,\n",
              " \"o'er\": 29,\n",
              " 'of': 28,\n",
              " 'one': 25,\n",
              " 'only': 42,\n",
              " 'or': 18,\n",
              " 'proud': 53,\n",
              " 'rains': 48,\n",
              " 'red': 57,\n",
              " 'said': 38,\n",
              " 'sharp': 21,\n",
              " 'sharp,': 14,\n",
              " 'so': 54,\n",
              " 'soul': 26,\n",
              " 'spoke': 6,\n",
              " 'spoke,': 43,\n",
              " 'still': 5,\n",
              " 'that': 56,\n",
              " \"that's\": 24,\n",
              " 'the': 15,\n",
              " 'there': 51,\n",
              " 'to': 36,\n",
              " 'truth': 39,\n",
              " 'weep': 55,\n",
              " 'who': 30,\n",
              " 'with': 22,\n",
              " 'yes,': 34,\n",
              " 'you': 58,\n",
              " 'yours': 47}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKbVGU5IdWdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_class = len(word_dict)\n",
        "max_len = len(vocab.split())\n",
        "n_hidden = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5brTKNKPdB-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_batch(vocab):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    \n",
        "    words = vocab.split()\n",
        "    for i, word in enumerate(words[:-1]):\n",
        "        input = [word_dict[n] for n in words[:(i+1)]]\n",
        "        input = input + [0] *(max_len - len(input))\n",
        "        \n",
        "        target = word_dict[words[i+1]]\n",
        "        \n",
        "        input_batch.append(np.eye(n_class)[input])\n",
        "        target_batch.append(target)\n",
        "     \n",
        "    return input_batch, target_batch\n",
        "\n",
        "\n",
        "\n",
        "#  -----------------------------------------\n",
        "#  | INPUT                | TARGET          |\n",
        "#  -----------------------------------------\n",
        "#  | word1                | word2           |\n",
        "#  | word1 + 2            | word3           |\n",
        "#  | word1 + 2 + 3        | word4           |\n",
        "#              .\n",
        "#              .\n",
        "#              .\n",
        "#  | word1 + 2 +.. |V|-1  | last word       |"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsdfY45sdD5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_batch, target_batch = make_batch(vocab)\n",
        "\n",
        "input_batch = Variable(torch.Tensor(input_batch))\n",
        "target_batch = Variable(torch.LongTensor(target_batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScgVziP6dFU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72FW0FJhdbZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=n_class, hidden_size=n_hidden, bidirectional=True)\n",
        "        self.W = nn.Parameter(torch.randn([n_hidden * 2, n_class]).type(dtype))\n",
        "        self.b = nn.Parameter(torch.randn([n_class]).type(dtype))\n",
        "\n",
        "    def forward(self, X):\n",
        "        input = X.transpose(0, 1)  # input : [n_step, batch_size, n_class]\n",
        "\n",
        "        hidden_state = Variable(torch.zeros(1*2, len(X), n_hidden))   # [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "        cell_state = Variable(torch.zeros(1*2, len(X), n_hidden))     # [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "\n",
        "        outputs, (_, _) = self.lstm(input, (hidden_state, cell_state))\n",
        "        outputs = outputs[-1]  # [batch_size, n_hidden]\n",
        "        model = torch.mm(outputs, self.W) + self.b  # model : [batch_size, n_class]\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUTKb7xudcmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Network()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24d6jg9ZddxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "2167897b-4ed4-4031-b984-f3dd8fb763ca"
      },
      "source": [
        "epochs = 10000\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    output = model(input_batch)\n",
        "    \n",
        "    loss = criterion(output, target_batch)\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"epoch: {epoch} ===> loss:{loss}\")\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 500 ===> loss:3.7432494163513184\n",
            "epoch: 1000 ===> loss:3.464881658554077\n",
            "epoch: 1500 ===> loss:3.467609167098999\n",
            "epoch: 2000 ===> loss:3.3478853702545166\n",
            "epoch: 2500 ===> loss:3.1607887744903564\n",
            "epoch: 3000 ===> loss:3.170344352722168\n",
            "epoch: 3500 ===> loss:3.047229051589966\n",
            "epoch: 4000 ===> loss:2.997220277786255\n",
            "epoch: 4500 ===> loss:2.9603426456451416\n",
            "epoch: 5000 ===> loss:2.9192965030670166\n",
            "epoch: 5500 ===> loss:2.8676185607910156\n",
            "epoch: 6000 ===> loss:2.7643117904663086\n",
            "epoch: 6500 ===> loss:2.1128740310668945\n",
            "epoch: 7000 ===> loss:1.912989616394043\n",
            "epoch: 7500 ===> loss:1.7553372383117676\n",
            "epoch: 8000 ===> loss:1.631020426750183\n",
            "epoch: 8500 ===> loss:2.3829903602600098\n",
            "epoch: 9000 ===> loss:2.0513007640838623\n",
            "epoch: 9500 ===> loss:1.84079110622406\n",
            "epoch: 10000 ===> loss:1.7131637334823608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vbWFEfjhPxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = \"the lord has sharp red claws\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajknlAr6kiLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = test_data.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wweeKgyKhzuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_batch = []\n",
        "\n",
        "\n",
        "words = test_data.split()\n",
        "for i, word in enumerate(words[:-1]):\n",
        "    input = [word_dict[n] for n in words[:(i+1)]]\n",
        "    input = input + [0] *(max_len - len(input))\n",
        "    \n",
        "    test_input_batch.append(np.eye(n_class)[input])\n",
        "\n",
        "test_input_batch = Variable(torch.Tensor(test_input_batch))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaNPzh5XlBgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "77fa8642-9d11-4220-cee9-0d2a6aaf59ce"
      },
      "source": [
        "predict = model(test_input_batch).data.max(1, keepdim=True)[1]\n",
        "predict"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[28],\n",
              "        [50],\n",
              "        [28],\n",
              "        [23],\n",
              "        [23]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwrLuWvhlJeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8ce22a6-1e37-45ee-8f9e-2fae89e557cd"
      },
      "source": [
        "print(test_data,\" --> \", [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the lord has sharp red claws  -->  ['of', 'long', 'of', 'a', 'a']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}